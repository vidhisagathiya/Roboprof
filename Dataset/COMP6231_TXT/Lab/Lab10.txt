COMP6721 Applied Artificial Intelligence (Fall 2023)Lab Exercise #10: Introduction to NLPSolutionsQuestion 1 Assume that we are working with the Shloutan language. If you don’t knowShloutan, don’t worry; it is a simple language made of only 5 words: loolanikee aloka bibi vo.You want to build a word language model for Shloutan. The training corpusthat you use is the following:“Loola nikee. Aloka bibi vo. Vo bibi loola. Loola nikee bibi vo. Vo. Vo. Alokabibi loola. Loola aloka aloka. Loola loola. Nikee nikee nikee. Bibi vo. Bibi vo.Vo Vo. Nikee loola.”You can ignore case distinctions and sentence boundaries when answering thefollowing questions.(a) What is the value of P(vo | bibi)?P (vo|bibi) = freq(bibi vo)∑wifreq(bibi wi)= 46(b) What is the value of P(bibi vo)?P (bibi vo) = freq(bibi vo)∑wj∑wifreq(wj wi)= 4321(c) Build a bigram language model based on this training corpus. Show thefrequencies and the probabilities for each bigram.Frequenciesloola nikee aloka bibi voloola 3 3 1 0 0nikee 1 2 1 2 0aloka 1 0 1 2 0bibi 2 0 0 0 4vo 0 1 1 2 5Conditional Probabilitiesloola nikee aloka bibi voloola 0.43 0.43 0.14 0 0nikee 0.17 0.33 0.17 0.33 0aloka 0.25 0 0.25 0.50 0bibi 0.33 0 0 0 0.67vo 0 0.11 0.11 0.22 0.56(d) Smooth your bigram language model using “add 0.5”. Show the frequenciesand the probabilities for each bigram.Frequenciesloola nikee aloka bibi voloola 3.5 3.5 1.5 0.5 0.5nikee 1.5 2.5 1.5 2.5 0.5aloka 1.5 0.5 1.5 2.5 0.5bibi 2.5 0.5 0.5 0.5 4.5vo 0.5 1.5 1.5 2.5 5.5Conditional Probabilitiesloola nikee aloka bibi voloola 0.37 0.37 0.16 0.05 0.05nikee 0.18 0.29 0.18 0.29 0.06aloka 0.23 0.08 0.23 0.38 0.08bibi 0.29 0.06 0.06 0.06 0.53vo 0.04 0.13 0.13 0.22 0.482(e) Using each language model from parts (c) and (d), which of the followingtwo sentences is more probable. Show all your work.sentence 1: Aloka vo nikee aloka.Bigrams: (aloka vo), (vo nikee), (nikee aloka)Model (c): 0 × 0.11 × 0.17 = 0Model (d): 0.08 × 0.13 × 0.18 ≈ 0.0019sentence 2: Vo nikee nikee aloka.Bigrams: (vo nikee), (nikee nikee), (nikee aloka)Model (c): 0.11 × 0.33 × 0.17 ≈ 0.0062Model (d): 0.13 × 0.29 × 0.18 ≈ 0.0068Sentence 2 is more probable using either model.3Question 2 Consider the following context-free grammar:S → NP VPVP → VVP → V NPVP → VP PPNP → DET NNP → PNNP → NP PPPP → PREP NPN → lionN → knifeN → zooV → attackedPN → JaneDET → theDET → aPREP → withPREP → in(a) Generate all possible parse trees for the following sentence:i Jane attacked a lion with a knifeThere are two possible parse trees:SNPPNJaneVPVattackedNPNPDETaNlionPPPREPwithNPDETaNknifeSNPPNJaneVPVPVattackedNPDETaNlionPPPREPwithNPDETaNknifeIn the sentence “Jane attacked a lion with a knife,” the context-freegrammar rules lead to two different parse trees, demonstrating syntacticambiguity. The left tree utilizes the rule NP → NP PP, interpreting“with a knife” as part of the noun phrase, resulting in “a lion with aknife.” This suggests the lion, associated with the knife, is the object ofthe attack. The right tree follows the rule VP → VP PP, where “witha knife” modifies the verb phrase “attacked a lion,” indicating thatJane used a knife in the attack. These variations highlight how specificgrammar rules, can yield different meanings from the same sentencestructure in natural language processing.4Question 3 Consider the following sentences as training set for disambiguating the senseof the word light.Sentence SenseThere is a ray of light even if it is dim. Sense1This faint ray of light is barely enough to see. Sense1It needs to be light in weight to be portable. Sense2I can see dim red light coming from that room. Sense1This laptop is light enough to carry around. Sense2I am not hurt since I was hit by something as light as a candle. Sense2There is a faint hint of light at the end of the street. Sense1But the room was bright and light from the candle was warm as it fell on thesurroundings.Sense1My bright red overcoat is light but fairly warm. Sense2This red candle stand is light enough to carry it to the room. Sense2Further consider this list of stop words:a, and, are, as, at, be, for, from, in, is, it, if, of, that, this, the, to, wasUsing a Naive Bayes approach with:• a context window of ± 3 words,• a vocabulary with the size of 31,• smoothing with the value of 0.2, and• stop-word removalCalculate the scores of each possible sense and find the most probable sense of the wordlight in the following sentence:In her dark red room, that dim light from the candle was warm enough.The sentence with the word to disambiguate-In her dark red room , that dim light from the candle was warm enough .Note: The stop words have been depicted as strike outs, since they will notbe considered in predicting the sense. The words in the box are the words thatare a part of the sentence and lie within the context window. The probabilitiesof these words for each sense in the training set will be considered.Each of the words in the box above is also highlighted (boxed) in each of thetraining sentences below, when it lies within the context window of the wordwe are trying to disambiguate:There is a ray of light even if it is dim .This faint ray of light is barely enough to see.It needs to be light in weight to be portable.5I can see dim red light coming from that room .This laptop is light enough to carry around.I am not hurt since I was hit by something as light as a candle .There is a faint hint of light at the end of the street.But the room was bright and light from the candle was warm as it fell onthe surroundings.My bright red overcoat is light but fairly warm .This red candle stand is light enough to carry it to the room .P(Sense1) = 5/10 = 1/2 = 0.5P(Sense2) = 5/10 = 1/2 = 0.5P(red|Sense1) = 1 + 0.225 + (31× 0.2) = 1.231.2 = 0.038461538P(room|Sense1) = 2 + 0.225 + (31× 0.2) = 2.231.2 = 0.070512821P(dim|Sense1) = 2 + 0.225 + (31× 0.2) = 2.231.2 = 0.070512821P(candle|Sense1) = 1 + 0.225 + (31× 0.2) = 1.231.2 = 0.038461538P(warm|Sense1) = 1 + 0.225 + (31× 0.2) = 1.231.2 = 0.038461538P(enough|Sense1) = 1 + 0.225 + (31× 0.2) = 1.231.2 = 0.038461538P(red|Sense2) = 2 + 0.223 + (31× 0.2) = 2.229.2 = 0.075342466P(room|Sense2) = 1 + 0.223 + (31× 0.2) = 1.229.2 = 0.04109589P(dim|Sense2) = 0 + 0.223 + (31× 0.2) = 0.229.2 = 0.006849315P(candle|Sense2) = 2 + 0.223 + (31× 0.2) = 2.229.2 = 0.075342466P(warm|Sense2) = 1 + 0.223 + (31× 0.2) = 1.229.2 = 0.04109589P(enough|Sense2) = 2 + 0.223 + (31× 0.2) = 2.229.2 = 0.075342466score(Sense1)= log(Sense1)+log(P (red|Sense1))+log(P (room|Sense1))+log(P (dim|Sense1)+log(P (candle|Sense1) + log(P (warm|Sense1) + log(P (enough|Sense1)= log(0.5)+log(0.038461538)+log(0.070512821)+log(0.070512821)+log(0.038461538)+log(0.038461538) + log(0.038461538)= −8.2643872146score(Sense2)= log(Sense2)+log(P (red|Sense2))+log(P (room|Sense2))+log(P (dim|Sense2)+log(P (candle|Sense2) + log(P (warm|Sense2) + log(P (enough|Sense2)= log(0.5)+log(0.075342466)+log(0.006849315)+log(0.04109589)+log(0.075342466)+log(0.04109589) + log(0.075342466)= −8.606666574Since score(Sense1) > score(Sense2), Sense1 is more probable.7Question 4 Preprocessing text is a very crucial step for any NLP related task. There aremany frameworks (GATE1, UIMA2) and libraries (CoreNLP3, NLTK4, spaCy5)available out there to facilitate text analysis.Today we will be looking into spaCy to get you started with the basic steps.Installing spaCy. To install spaCy using Conda, use:conda install -c conda-forge spacyAfter the installation, execute the following command to verify that you haveinstalled spaCy version 3 or upper.python -m spacy infoDownloading language models. Not all languages are preprocessed in thesame way. Depending on the language, tokenization, sentence splitting, POStagging, etc. varies. To facilitate analyzing different languages and genres,spaCy provides different pre-trained language pipelines to work with.6 Forstarters, we will be working with the basic English model. We can downloadthe model with the following command:python -m spacy download en_core_web_smLet’s start coding! Use the following to import the spaCy library and loadthe language model:import spacynlp = spacy.load("en_core_web_sm")Now let’s try to preprocess the text in your worksheet and check if the POStags we assigned are what spaCy returns as well:doc = nlp("I prefer a direct flight to Chicago.")Depending on the language model and sentence provided as input, spaCy out-puts an object doc, in our case with a variety of annotations encoded within.Linguistic annotations are available as token attributes. Let’s try to print somebasic attributes:1https://gate.ac.uk/2http://uima.apache.org/3https://stanfordnlp.github.io/CoreNLP/index.html4https://www.nltk.org/book/5https://spacy.io/usage/spacy-1016https://spacy.io/usage/models8https://gate.ac.uk/http://uima.apache.org/https://stanfordnlp.github.io/CoreNLP/index.htmlhttps://www.nltk.org/book/https://spacy.io/usage/spacy-101https://spacy.io/usage/modelsfor token in doc:print(token.text, token.lemma_, token.tag_, token.dep_)(a) Now try to process the following paragraph to see how spaCy performssentence splitting:“Superman was born on the planet Krypton and was given thename Kal-El at birth. As a baby, his parents sent him to Earthin a small spaceship moments before Krypton was destroyed ina natural cataclysm. His ship landed in the American country-side, near the fictional town of Smallville. He was found andadopted by farmers Jonathan and Martha Kent, who named himClark Kent. Clark developed various superhuman abilities, suchas incredible strength and impervious skin. His adoptive parentsadvised him to use his abilities for the benefit of humanity, andhe decided to fight crime as a vigilante. To protect his privacy,he changes into a colorful costume and uses the alias "Superman"when fighting crime. Clark Kent resides in the fictional Amer-ican city of Metropolis, where he works as a journalist for theDaily Planet. Superman’s supporting characters include his loveinterest and fellow journalist Lois Lane, Daily Planet photogra-pher Jimmy Olsen and editor-in-chief Perry White. His classicfoe is Lex Luthor, who is either a mad scientist or a ruthlessbusinessman, depending on the story.”Start by processing the text:doc = nlp(text)This performs sentence splitting as part of the analysis pipeline. Now addcode to print all the resulting sentences.sentence_spans = list(doc.sents)for sentences in sentence_spans:print(sentences)(b) In addition to the constituent parse trees discussed in the lecture andQuestion 2 above, dependency parsing7 is another formalism used in En-glish grammars. In dependency parse trees, each token (word) is con-nected to another by a single arc, where the arc’s label indicates the syn-tactic relationship between them. The starting node of the arc is knownas the Governor (or head in spaCy terminology), and the endpoint is theDependant (called child in spaCy). Each ’Dependant/Child’ can have only7See https://web.stanford.edu/~jurafsky/slp3/18.pdf and https://spacy.io/usage/linguistic-features#dependency-parse for more details on dependency parse trees9https://web.stanford.edu/~jurafsky/slp3/18.pdfhttps://spacy.io/usage/linguistic-features#dependency-parsehttps://spacy.io/usage/linguistic-features#dependency-parseone ’Governor/Head,’ but a ’Governor/Head’ may have multiple depen-dents. Every dependency tree also has a root, typically the main verb ofthe sentence, and the arcs point from heads to their children.When you process text with spaCy’s nlp function (like in doc = nlp(text)),a dependency parse tree is automatically created for each sentence. Now,try to use spaCy’s “displaCy visualizer”8 to visualize the dependency parsetree for the sentence given in your worksheet — the result should look likeFigure 1.Figure 1: Dependency parse tree created by spaCy for the sentence we used on the worksheetimport spacyfrom spacy import displacynlp = spacy.load("en_core_web_sm")doc = nlp("I prefer a direct flight to Chicago.")displacy.serve(doc, style="dep")You should be able to visualize the graph by clicking the link from the runcommand window or by opening your browser at http://0.0.0.0:5000As depicted in the graph, the token which has no arrows points pointed at(or the token from which the arcs starts) is known as the root, which is themain action in a sentence. Then, nsubj (i.e., noun subject) refers to themain subject of the sentence, which is “I” in our case and dobj (i.e., directobject) refers to the object that we are talking about in a sentence; hereit is about “flight”. The tokens “a” and “direct” are determiners (det)and adjective modifiers (amod), respectively; hence, for the token “flight”you see the arc starting from here.Through a dependency graph, you can see how tokens are connected withone another and you can extract the main subject, object and the actiongiven a sentence, no matter how long it is. This is an important aspectin many language related tasks, for example to summarize a text.8See https://spacy.io/usage/visualizers10http://0.0.0.0:5000https://spacy.io/usage/visualizers(c) Now we will look at Named Entity Recognition (NER), an essential taskin natural language processing (NLP) that involves identifying and clas-sifying proper nouns in text into predefined categories such as names ofpersons, organizations, locations, expressions of times, quantities, mone-tary values, percentages, etc. NER is crucial for understanding the con-tent of a document by highlighting the key entities and is widely used ininformation extraction, content classification, and data analysis.Using spaCy, we can easily perform NER with minimal coding. spaCy’sNER model is pre-trained on a large corpus and can recognize a widerange of entity types. Start by processing the following text with spaCyand explore the identified named entities:text = "Apple is looking at buying U.K. startup for $1 billion. Barack↪→ Obama visited Apple headquarters in California."Process this text using the spaCy pipeline and iterate through the namedentities in the processed document, which are stored in the ents propertyof a doc object. For each entity, print out its text and the entity type ithas been classified as. For example, “Apple” should be recognized as anOrganization and “Barack Obama” as a Person.To print out the detected entities, you can use:for ent in doc.ents:print(ent.text, ent.start_char, ent.end_char, ent.label_)After processing the text with spaCy, the model identifies and catego-rizes each entity. For example, ’Apple’ is recognized as an organization,’U.K.’ as a geopolitical entity, ’1 billion’ as a monetary value, and ’BarackObama’ as a person. This exercise demonstrates spaCy’s capability inaccurately identifying and classifying entities in text, which is crucial forvarious NLP applications.You can also use displayCy to visualize the detected entities:displacy.serve(doc, style='ent')This lab marks your initial foray into Natural Language Processing (NLP), afoundational aspect of AI that bridges language and technology. The expe-rience gained with spaCy is crucial for understanding how machines interprethuman language. The practical skills you’ve developed are applicable in vari-ous real-world scenarios, from enhancing search engine algorithms to improvingautomated customer support systems. NLP’s relevance spans multiple indus-tries, including healthcare, finance, and media, where insights from text dataare invaluable. As you delve deeper into NLP, you’ll find the field repletewith opportunities for innovation and advancement. Continue building uponthese skills, and you may soon find yourself adept at creating applications thatsignificantly impact the way we interact with technology in language-drivencontexts.11