AI: Adversarial Search1Artificial Intelligence: Adversarial Search2Search for Adversarial ScenariosAdversarial: non-cooperative (competing) entities Game Playing Tic-Tac-Toe, Chess, Go, ... Auction/Bidding Systems e.g., real-time bidding for online ad space Network Security Intruder vs. defender of network integrity Natural Resource Management Competing for limited resources (fish, water, ...) Military Tactics3Game Playing ExamplesGOchess tic-tac-toe4Today State Space Search for Game Playing MiniMax Alpha-beta pruning Stochastic Games Where we are today6Adversarial SearchClassical application for heuristic search simple games: exhaustively searchable complex games: only partial search possible additional problem: playing against opponentHere, we look at 2-player adversarial games win, lose, or tie7Types of Games Perfect Information A game with the perfect information is that in which agents can look into the complete board. Agents have all the information about the game, and they can see each other moves also.  Examples: Chess, Checkers, Go, etc. Imperfect Information Game state only partially observable, choices by opponent are not visible (hidden) Example: Battleship, Stratego, many card games, etc.8Types of Games (II)Deterministic games No games of chance (e.g., rolling dice) Examples: Chess, Tic-Tac-Toe, Go, etc.Non-deterministic games Games with unpredictable (random) events (involving chance or luck) Example: Backgammon, Monopoly, Poker, etc.9Types of Games (III)Zero-Sum Game If the total gains of one player are added up, and the total losses are subtracted, they will sum to zero(example: cutting a cake)  A gain by one player must be matched by a loss by the other player One player tries to maximize a single value, the other player tries to minimize it Examples: Checkers, Chess, etc.Non-Zero-Sum Game Win-Win or Lose-Lose type games Famous example: The Prisoner’s Dilemmahttps://en.wikipedia.org/wiki/Prisoner%27s_dilemmahttps://en.wikipedia.org/wiki/Prisoner%27s_dilemma10Today State Space Search for Game Playing MiniMax Alpha-beta pruning Stochastic games Where we are today11Example: Game of NimRules 2 players start with a pile of tokens (here: 7) move: split (any) existing pile into two non-empty differently-sized piles game ends when no pile can be unevenly split player who cannot make the move losesExample Start: MIN: MAX: → Worksheet #2 (“Game of Nim”)12State Space of Game Nim start with one pile of tokens each step has to divide one pile of tokens into 2 non-empty piles of different size player without a move left loses gamesource: G. Luger (2005) 13MiniMax Search Game between two opponents, MIN and MAX MAX tries to win, and  MIN tries to minimize MAX’s score Existing heuristic search methods do not work would require a helpful opponent Need to incorporate “hostile” moves into search strategyMaxMinMaxMinMaxMin14Exhaustive MiniMax Search  For small games where exhaustive search is feasible Procedure:1. build complete game tree2. label each level according to player’s turn (MAX or MIN)3. label leaves with a utility function to determine the outcome of the game e.g., (0, 1) or (-1, 0, 1)4. propagate this value up: if parent=MAX, give it max value of children if parent=MIN, give it min value of children5. select best next move for player at root as the move leading to the child with the highest value (for MAX) or lowest values (for MIN) 15Exhaustive MiniMax for NimBold lines indicateforced win for MAX source: G. Luger (2005) 0: win for MIN1: win for MAX16n-ply MiniMax with Heuristic Exhaustive search for interesting games is rarely feasible Search only to predefined level called n-ply look-ahead n is number of levels No exhaustive search nodes evaluated with heuristics and not win/loss indicates best state that can be reached horizon effect Games with opponent simple strategy: try to maximize difference between players using a heuristic function e(n)Heuristic Function for 2-player games Simple strategy:  try to maximize difference between MAX’s game and MIN’s game  Typically called e(n) e(n) is a heuristic that estimates how favorable a node n is for MAX e(n) > 0 --> n is favorable to MAX  e(n) < 0 --> n is favorable to MIN  e(n) = 0 --> n is neutral 17Choosing a Heuristic Function e(n)18 19MiniMax with Fixed Ply DepthLeaf nodes show the actual heuristic value e(n)source: G. Luger (2005) → Worksheet #2 (“MiniMax”)Example: e(n) for Tic-Tac-Toe Possible e(n)              number of rows, columns, and diagonals open for MAX                    - number of rows, columns, and diagonals open for MIN               +∞, if n is a forced win for MAX                  -∞, if n is a forced win for MINe(n) = 8-8 = 0 e(n) = 6-4 = 2 e(n) = 3-3 = 024e(n) =   → Worksheet #2 (“MiniMax Heuristic for Tic-Tac-Toe”)26Two-ply MiniMax for Opening Movesource: G. Luger (2005) Tic-Tac-Toe treeat horizon = 227Two-ply MiniMax: MAX’s possible 2nd  movessource: G. Luger (2005) 29Two-ply minimax: MAX’s move at end?source: G. Luger (2005) → Worksheet #2 (“Two-ply MiniMax”)30Today State Space Search for Game Playing MiniMax Alpha-beta pruning Stochastic games Where we are today31Alpha-Beta Pruning Optimization over MiniMax, that: ignores (cuts off, prunes) branches of the tree that cannot possibly lead to a better solution reduces branching factor allows deeper search with same effort32Alpha-Beta Pruning: Example 1 With MiniMax, we look at all possible nodes at the n-ply depth With α-β pruning, we ignore branches that could not possibly contribute to the final decisionB will be >= 5So we can ignore B’s right branch, because A must be 3D will be <= 0But C will be >= 3So we can ignore D’s right branchE will be <= 2.So we can ignore E’s right branchBecause C will be 3.source: G. Luger (2005) A=min(3, max(5,?)) C=max(3, min(0,?), min(2,?))Alpha-Beta Pruning Algorithm33 α : lower bound on the final backed-up value. β : upper bound on the final backed-up value. Alpha pruning:  eg.  if MAX node's α = 6, then the search can prune branches from a MIN descendant that has a β <= 6.   if child β <= ancestor α → prune   Beta pruning:  eg. if a MIN node's β = 6, then the search can prune branches from a MAX descendant that has an α >= 6.  if ancestor β  <= child α → prunevalue ≥ 6 value ≤ 5 incompatible… so stop searching the right branch; the value cannot come from there! MAXMIN value ≤ 6  value ≥ 7MINMAXb=6a =-∞a =7 b=+∞b=+∞a =6b=5a =-∞incompatible… so stop searching the right branch; the value cannot come from there! 34Alpha-Beta Pruning Algorithm01 function alphabeta(node, depth, α, β, maximizingPlayer)02      if depth = 0 or node is a terminal node03          return the heuristic value of node04      if maximizingPlayer05          v := -∞06          for each child of node07              v := max(v, alphabeta(child, depth - 1, α, β, FALSE))08              α := max(α, v)09              if β ≤ α10                  break (* β cut-off *)11          return v12      else13          v := ∞14          for each child of node15              v := min(v, alphabeta(child, depth - 1, α, β, TRUE))16              β := min(β, v)17              if β ≤ α18                  break (* α cut-off *)19          return vInitial call:alphabeta(origin, depth, -∞, +∞, TRUE)source: http://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning Example with tic-tac-toe35min levelmax levelsource: robotics.stanford.edu/~latombe/cs121/2003/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmExample with tic-tac-toee(n) = 236max levelmin levelvalue ≤ 2source: robotics.stanford.edu/~latombe/cs121/2003/home.htmb=2a =-∞http://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmExample with tic-tac-toee(n) = 1e(n) = 237value ≤ 2 1min levelmax levelsource: robotics.stanford.edu/~latombe/cs121/2003/home.htmb=2 1a =-∞http://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmExample with tic-tac-toe value ≥ 1e(n) = 1 value = 1e(n) = 238min levelsource: robotics.stanford.edu/~latombe/cs121/2003/home.htmmax levelb=+∞a =1http://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmExample with tic-tac-toe value ≥ 1e(n) = 1 value = 1e(n) = 2 e(n) = -1 value ≤ -1 39min levelmax levelsource: robotics.stanford.edu/~latombe/cs121/2003/home.htmb=+∞a =1b=-1a =-∞http://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmExample with tic-tac-toee(n) = 1b = 1e(n) = 2 e(n) = -1 value ≤ -1 child β <= ancestor α → stop search40incompatible… so stop searching the right branch; the value cannot come from there! source: robotics.stanford.edu/~latombe/cs121/2003/home.htmb=+∞a =1b=-1a =-∞ value ≥ 1http://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmhttp://robotics.stanford.edu/~latombe/cs121/winter02/home.htmMax-------------------------------------------------------------------------------------------------------Min-------------------------------------------------------------------------------------------------------Max-------------------------------------------------------------------------------------------------------Min--------------------------------------------------------------------------------------------------------41Alpha-Beta Pruning: Example 2source: http://en.wikipedia.org/wiki/File:AB_pruning.svg    ≤5=5 =6=5≥5=7≤7=4≤4 ≤4=5≤5 =3=3=3=3≥3 =6=6≥6=6≤6 ≤6=6≤6=7=7=7=6≥6 =5=5=5≤5=6✓x x✓✓ x42Alpha-Beta Pruning: Example 2source: http://en.wikipedia.org/wiki/File:AB_pruning.svgAlpha-Beta Pruning: Example 344Step 1Step 2Step 3→ Worksheet #2 (“Alpha-Beta Pruning”)70Efficiency of Alpha-Beta Pruning Depends on the order of the siblings In worst case:  alpha-beta provides no pruning In best case:  branching factor is reduced to its square rootAlpha-Beta: Best ordering71Original (arbitrary) game treeBest ordering for alpha-betaAlpha-Beta: Best ordering best ordering: 1. children of MIN : smallest node first2. children of MAX: largest node first72Alpha-Beta: Best ordering best ordering: 1. children of MIN : smallest node first2. children of MAX: largest node first73Alpha-Beta: Best ordering74 best ordering: 1. children of MIN : smallest node first2. children of MAX: largest node firstAlpha-Beta: Best ordering75Alpha-Beta: Best ordering76Alpha-Beta: Best ordering778 nodes explored out of 27 78Today State Space Search for Game Playing MiniMax Alpha-beta pruning Stochastic Games Where we are todayBackgammonsource: Russel & Norvig (2010) Stochastic (Non-Deterministic)Games Search tree for games of chance  white can calculate its own legal moves but it does not know what black will roll... Idea: add chance nodes to the search tree branches indicate possible dice rolls each branch labeled with the roll and its probability(e.g., 1/6 for a single dice roll)Search Tree for BackgammonEXPECTIMINIMAX Algorithm Calculating EXPECTIMINIMAX Like MiniMax, but using the weighted sum for Chance nodes: r is a possible dice roll (or other random event) P(r) the probability of the event Result(s, r) is the same state s with dice roll result r Note: very expensive due to the high branching factor! See https://en.wikipedia.org/wiki/Expectiminimaxfor the whole algorithm∑ P (r ) Expectiminimax (Result (s , r ) )https://en.wikipedia.org/wiki/Expectiminimax87Today State Space Search for Game Playing MiniMax Alpha-beta pruning Stochastic Games Where we are today1992-1994 - Checkers: Tinsley vs. Chinook Marion TinsleyWorld champion for over 40 yearsIn 2007, Schaeffer announced that checkers was solved, and anyone playing against Chinook would only be able to draw, never win.ChinookDeveloped by Jonathan Schaeffer, professor at the U. of Alberta1992: Tinsley beat Chinook in 4 games to 2,           with 33 draws. 1994: 6 draws  VS88Play against Chinook: http://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemohttp://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemohttp://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemohttp://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemohttp://games.cs.ualberta.ca/cgi-bin/player.cgi?nodemo1997 - Othello: Murakami vs. LogistelloLogistello beat Murakami by 6 games to 0Takeshi MurakamiWorld Othello (aka Reversi) championVSLogistellodeveloped by Michael Buroruns on a standard PChttps://skatgame.net/mburo/log.html (including source code)89https://skatgame.net/mburo/log.html1997- Chess: Kasparov vs. Deep BlueGarry Kasparov50 billion neurons2 positions/secVSDeep Blue32 RISC processors + 256 VLSI chess engines200,000,000 pos/secDeep Blue wins by 3 wins, 1 loss, and 2 draws902003 - Chess: Kasparov vs. Deep JuniorMatch ends in a 3/3 tie!Garry Kasparovstill 50 billion neuronsstill 2 positions/secVSDeep Junior8 CPU, 8 GB RAM, Win 2000 2,000,000 pos/secAvailable at $10091922016 – Go: AlphaGo vs Lee Se-dol GO was always considered a much harder game to automate than chess because of its very high branching factor (35 for chess vs 250 for Go!)https://www.theverge.com/2016/3/15/11213518/alphago-deepmind-go-match-5-result In 2016, AlphaGo beat Lee Sedol in a five-game match of GO.   In 2017 AlphaGo beat Ke Jie, the      world No.1 ranked player at the time uses a Monte Carlo tree search algorithm to find its moves based on knowledge previously "learned" by deep learning932017 – AlphaGo Zero & AlphaZeroAlphaGo Zero learned the Game by itself, without input of human games Became better than all old versions after 40 days of training In the first three days, AlphaGo Zero played 4.9 million games against itself using reinforcement learningAlphaZero can learn other games, like Chess and Shogi In 2018, it beat the then-best chess program, Stockfish 8 in a 100-game tournament Trained using 5,000 tensor processing units (TPUs), run on four TPUs and a 44-core CPU during matches942018 – AlphaZero vs Stockfish 8Game commentary: https://www.youtube.com/watch?v=nPexHaFL1uohttps://www.youtube.com/watch?v=nPexHaFL1uo97Today State Space Search for Game Playing MiniMax Alpha-beta pruning Stochastic games Where we are today