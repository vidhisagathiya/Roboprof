COMP 6721 Applied Artificial Intelligence (Fall 2023)Worksheet #4: Decision Trees & k-means ClusteringDecision Tree. Given the following training data:Create a decision tree that decides if a student will get an ‘A’ this year, based on an input feature vector X.(Note: check that your tree would return the correct answer for all of the training data above.)Your Decision TreeInformation Content. The information content of an event x with P (x) > 0 is defined as:−P (x) · log2(P (x))An impossible event (P (x) = 0) is defined as having an information content of 0. What’s the information contentof a certain event (P (x) = 1)?COMP6721 Worksheet: Decision Trees & k-means Clustering Fall 2023Entropy. Using the definition of Entropy for a discrete random variable X with possible outcomes x1, x2, . . . , xn:H(X) = −n∑i=1p(xi) · log2 p(xi)compute the entropy for the outcome of the color in Roulette, where you have the numbers 1–36 (half red, halfblack) and the 0 with the color green:H(X) =Note: make sure you use log2(x); if you have a calculator with log10 only, you can compute it using the formulalog2(x) = log10(x)/ log10(2).Information Gain. Compute the Information Gain (IG) for the following training data when splitting using the“Size” attribute:gain(S,A)= H(S)−H(S|A)= H(S)−∑v∈values(A)|Sv||S|·H(Sv)H(S|Size) =gain(Size) = H(S)−H(S|Size) =F-Measure. Compute the F-Measure, which combines precision and recall into a single number, using β = 1(called F1-measure, P and R have an equal weight):F1 =2 · P ·RP +RFor the systems s2, s3 from the previous lecture worksheet:1. s2 : P = 100%, R = 60%⇒ F1 =2. s3 : P = 71%, R = 100%⇒ F1 =k-Means Clustering. Here is a dataset with two attributes, to be grouped into two clusters. Compute thedistance d(~p, ~q) =√∑ni=1(pi − qi)2 of each data point to the two initial centroids and assign each point to itsclosest cluster:Centroida1 a2Cluster 1 1.0 1.0Cluster 2 5.0 7.0a1 a2 Distance to C1 Distance to C2 ClusterData1 1.5 2.0Data2 3.0 4.0Data3 4.5 5.0Data4 3.5 4.5Now calculate the new centroids for each cluster:Cluster 1, new centroid =Cluster 2, new centroid =